{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo51_TextTokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9bJCDjdlgG6",
        "colab_type": "text"
      },
      "source": [
        "# **Spit some [tensor] flow**\n",
        "\n",
        "We need to learn the intricacies of tensorflow to master deep learning\n",
        "\n",
        "`Let's get this over with`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUYIb-m3UdGP",
        "colab_type": "text"
      },
      "source": [
        "## So we OHE the last NLP problem, why not do the same and feed it to the neural network? Well because, features in a language, are not independent. \n",
        "\n",
        "\n",
        "Let's explore this: \n",
        "\n",
        "The quick brown fox jumps over __________________\n",
        "\n",
        "See you know the end of this sentence because you know the words right? \n",
        "\n",
        "well wb this: \n",
        "\n",
        "over _____________________\n",
        "\n",
        "Now we don't know the end of this sentence. \n",
        "\n",
        "So in tensorflow, to save computations, we have the embedding layer: \n",
        "\n",
        "### Step 1: Words to ints\n",
        "\n",
        "Nothing deep about deep learning ----> 13 43 32 43 98\n",
        "\n",
        "### Step 2: Ints to word vector \n",
        "\n",
        "13 43 32 43 98 ------> [0.9, 1.2] [-0.4, 0.2] [0.3, 0.3] [-0.4, 0.2] [0.2, 0.5] \n",
        "\n",
        "T -----> T x D\n",
        "\n",
        "\n",
        "### We can use word2vec to make sure the embedding layer has similar words close to each other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQwc0re5mFld",
        "colab_type": "code",
        "outputId": "71fad5d2-043a-43c4-a43e-e628a1d13c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaBxIWkog_i-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dropout, Dense, Flatten, SimpleRNN, GRU, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zyXereWghe2",
        "colab_type": "code",
        "outputId": "d1cd7728-4032-45a1-a44c-921f827b7f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Get the dataset \n",
        "data = [\"Hello world\", \"I ain't saying hello to you\", \"what's up with all the hellos\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f379ce5ef3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample_data/train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mCu_N19jxIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SIZE = 10000\n",
        "tokenizer = Tokenizer(num_words=MAX_SIZE)\n",
        "tokenizer.fit_on_texts(data)\n",
        "sequences = tokenizer.texts_to_sequences(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3QvZdR-kBkr",
        "colab_type": "code",
        "outputId": "16c4729f-1829-49df-c637-317f493730c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2], [3, 4, 5, 1, 6, 7], [8, 9, 10, 11, 12, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDZzcRW0kEB6",
        "colab_type": "code",
        "outputId": "e9424bad-31e9-4a07-f31f-25df63f08be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tokenizer.word_index) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hello': 1, 'world': 2, 'i': 3, \"ain't\": 4, 'saying': 5, 'to': 6, 'you': 7, \"what's\": 8, 'up': 9, 'with': 10, 'all': 11, 'the': 12, 'hellos': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRDCGpWXkmW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Thl2GmrPkYrU",
        "colab_type": "code",
        "outputId": "c60ee797-23cc-4ef0-c6b6-830dc70d7b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "data = pad_sequences(sequences, \n",
        "                    maxlen = T, \n",
        "                    padding = 'post')\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  0  0]\n",
            " [ 5  1  6  7]\n",
            " [10 11 12 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiHr_ufZkvHE",
        "colab_type": "code",
        "outputId": "af2e2620-436d-46b9-caeb-e4aa2bd8069f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "data = pad_sequences(sequences, \n",
        "                    maxlen = T, \n",
        "                    padding = 'pre')\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  1  2]\n",
            " [ 5  1  6  7]\n",
            " [10 11 12 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-3NUDOLkxkS",
        "colab_type": "code",
        "outputId": "6b91dd71-92f3-4e65-b98d-78ecb0dac74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "data = pad_sequences(sequences, \n",
        "                    maxlen = T, \n",
        "                    truncating = 'pre',\n",
        "                    padding = 'post')\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  0  0]\n",
            " [ 5  1  6  7]\n",
            " [10 11 12 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNozYzSJlARs",
        "colab_type": "code",
        "outputId": "46910122-f330-421f-e461-ad263ec798fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "data = pad_sequences(sequences, \n",
        "                    maxlen = T, \n",
        "                    truncating = 'post',\n",
        "                    padding = 'post')\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  0  0]\n",
            " [ 3  4  5  1]\n",
            " [ 8  9 10 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}